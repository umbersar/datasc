df <- subset(df, select = c(labm_code,labr_value))
for(labmCode in unique(df$labm_code)){
filtered_df <- subset(df,labm_code==labmCode)
filtered_df <- droplevels(filtered_df)
# png(filename=paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
# boxplot(labr_value~labm_code,data=filtered_df,	xlab="labm_code", ylab="labr_value")
# dev.off()
pp <- ggplot2::ggplot(filtered_df,aes(x=labm_code, y=labr_value)) + ggplot2::geom_boxplot()
# pp
#ppp <-pp + geom_jitter()
# ppp
ggsave(paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,"_jitter.png"))
#break;
}
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
for(labmCode in unique(df$labm_code)){
filtered_df <- subset(df,labm_code==labmCode)
filtered_df <- droplevels(filtered_df)
# png(filename=paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
# boxplot(labr_value~labm_code,data=filtered_df,	xlab="labm_code", ylab="labr_value")
# dev.off()
pp <- ggplot2::ggplot(filtered_df,aes(x=labm_code, y=labr_value)) + ggplot2::geom_boxplot()
# pp
#ppp <-pp + geom_jitter()
# ppp
ggsave(paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,"_jitter.png"))
#break;
}
# filtered_df <- df[df$labm_code=="18F1_CU",]
# filtered_df <- subset(df,labm_code=="18F1_CU")
# levels(droplevels(df$labm_code))
# df1 <- droplevels(filtered_df)
# pp <- ggplot2::ggplot(df1,aes(x=labm_code, y=labr_value)) + ggplot2::geom_boxplot()
# pp
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
filtered_df <- df[df$labm_code=="4A1",]
filtered_df <- subset(df,labm_code=="4A1")
levels(droplevels(df$labm_code))
df1 <- droplevels(filtered_df)
View(df1)
df1 <- df1[, mean.score := mean(Score)]
library(data.table)
install.packages("data.table")
library(data.table)
as.data.table(df1)
dt1 <- library(data.table)
dt1 <- as.data.table(df1)
library(data.table)
dt1 <- as.data.table(df1)
dt1 <- dt1[, mean.score := mean(Score)]
dt1 <- dt1[, mean.score := mean(labr_value)]
dt1
View(dt1)
dt1 <- dt1[, mean.score := mean(labr_value), by = labmCode]
library(data.table)
dt1 <- as.data.table(df)
dt1 <- dt1[, mean.score := mean(labr_value), by = labmCode]
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
library(data.table)
dt1 <- as.data.table(df)
View(df1)
View(dt1)
dt1 <- dt1[, mean.score := mean(labr_value), by = labmCode]
dt1 <- as.data.table(df1)
dt1 <- dt1[, mean.score := mean(labr_value), by = labmCode]
dt1 <- dt1[, mean.score := mean(labr_value), by = labm_Code]
View(dt1)
dt1
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
dt1 <- as.data.table(df)
dt1 <- dt1[, mean.score := mean(labr_value), by = labm_Code]
View(dt1)
read.table('C:/temp/LabResults.csv', header = TRUE,sep =',' )
dt <- read.table('C:/temp/LabResults.csv', header = TRUE,sep =',' )
library(data.table)
dt <- as.data.table(dt)
dt <- dt[, mean.score := mean(labr_value), by = labm_Code]
dt
dt <- subset(dt, select = c(labm_code,labr_value))
dt <- dt[, mean.score := mean(labr_value), by = labm_Code]
dt
dt <- dt[, mean.score := mean(labr_value), by = labm_code]
dt <- dt[, mean.score := mean(labr_value), by = labm_Code]
dt <- dt[, mean.score := mean(labr_value), by = labm_code]
View(dt)
dt <- dt[, sd.score := sd(labr_value), by = labm_code]
dt <- dt[, outlier := abs(labr_value-mean.score) > 3 * sd.score, by = labm_code]
View(dt)
dt[, sum.outlier := sum(outlier), by = labm_code]
View(dt)
dt_fil <- subset(dt,labm_code=="4A1")
dt_fil
View(dt_fil)
dt_fil <- subset(dt,labm_code=="4A1" & outlier==TRUE)
dt_fil
dt_out <- subset(dt, outlier==TRUE)
dt_out
write.csv(dt_out)
dt <- read.table('C:/temp/LabResults.csv', header = TRUE,sep =',' )
library(data.table)
dt <- as.data.table(dt)
dt <- subset(dt, select = c(labm_code,labr_value))
dt <- dt[, mean.score := mean(labr_value), by = labm_code]
dt <- dt[, sd.score := sd(labr_value), by = labm_code]
dt <- dt[, max.score := max(labr_value), by = labm_code]
dt <- dt[, min.score := min(labr_value), by = labm_code]
dt <- dt[, outlier := abs(labr_value-mean.score) > 3 * sd.score, by = labm_code]
dt <- dt[, sum.outlier := sum(outlier), by = labm_code]
dt_out <- subset(dt, outlier==TRUE)
write.csv(dt_out, "C:/temp/possible_outlier.csv")
write.csv(dt, "C:/temp/stats.csv")
dt <- dt[, min.score := count(labr_value), by = labm_code]
dt <- dt[, min.score := length(labr_value), by = labm_code]
dt <- dt[, length.score := length(labr_value), by = labm_code]
dt <- read.table('C:/temp/LabResults.csv', header = TRUE,sep =',' )
library(data.table)
dt <- as.data.table(dt)
dt <- subset(dt, select = c(labm_code,labr_value))
dt <- dt[, mean.score := mean(labr_value), by = labm_code]
dt <- dt[, sd.score := sd(labr_value), by = labm_code]
dt <- dt[, max.score := max(labr_value), by = labm_code]
dt <- dt[, min.score := min(labr_value), by = labm_code]
dt <- dt[, length.score := length(labr_value), by = labm_code]
dt <- dt[, outlier := abs(labr_value-mean.score) > 3 * sd.score, by = labm_code]
dt <- dt[, sum.outlier := sum(outlier), by = labm_code]
dt_out <- subset(dt, outlier==TRUE)
write.csv(dt, "C:/temp/stats.csv")
write.csv(dt_out, "C:/temp/possible_outlier.csv")
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
for(labmCode in unique(df$labm_code)){
filtered_df <- subset(df,labm_code==labmCode)
filtered_df <- droplevels(filtered_df)
# png(filename=paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
# boxplot(labr_value~labm_code,data=filtered_df,	xlab="labm_code", ylab="labr_value")
# dev.off()
pp <- ggplot2::ggplot(filtered_df,aes(x=labm_code, y=labr_value)) + ggplot2::geom_jitter()
# pp
#ppp <-pp + geom_jitter()
# ppp
ggsave(paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
#break;
}
library(ggplot2)
df <- read.csv('C:/temp/LabResults.csv', header = TRUE,sep =',' )
#df <- read.csv('LabResults_incomplete.csv', header = TRUE,sep =',' )
#head(df)
df <- subset(df, select = c(labm_code,labr_value))
for(labmCode in unique(df$labm_code)){
filtered_df <- subset(df,labm_code==labmCode)
filtered_df <- droplevels(filtered_df)
# png(filename=paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
# boxplot(labr_value~labm_code,data=filtered_df,	xlab="labm_code", ylab="labr_value")
# dev.off()
pp <- ggplot2::ggplot(filtered_df,aes(x=labm_code, y=labr_value)) + ggplot2::geom_boxplot(outlier.shape = NA) + geom_jitter()
# pp
#ppp <-pp + geom_jitter()
# ppp
ggsave(paste("C:/Users/sin17h/Documents/NatSoilDataSc/test/",labmCode,".png"))
#break;
}
#integration using random numbers
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 10000
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
plot(x,y)
#integration using random numbers
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 100
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
plot(x,y)
plot(exp(2*cos(x-pi)))
plot(x,exp(2*cos(x-pi)))
#asas <- c(1,2,3)
#mean(asas>1)
phat.under <- mean(y<exp(2*cos(x-pi)))
phat.under * 16 * pi
plot(x,y)
plot(x,exp(2*cos(x-pi)))
#asas <- c(1,2,3)
#length(asas[asas>1])/N
phat.under <- length(y[y<exp(2*cos(x-pi))])/N
phat.under * 16 * pi
plot(x,y)
plot(x,exp(2*cos(x-pi)))
plot(exp(2*cos(x-pi)))
#integration using numerical integrate function
f <- function(x){exp(2*cos(x-pi))}
integrate(f,0,2*pi)
#from that distribution that fall under the curve we are trying to integrate. As we
#increase the number of points in the distribution, we get closer to
#expected answer.
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 10000
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
plot(x,y)
plot(x,exp(2*cos(x-pi)))
#asas <- c(1,2,3)
#mean(asas>1)
phat.under <- mean(y<exp(2*cos(x-pi)))
phat.under * 16 * pi
#from that distribution that fall under the curve we are trying to integrate. As we
#increase the number of points in the distribution, we get closer to
#expected answer.
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 100000
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
#asas <- c(1,2,3)
#mean(asas>1)
phat.under <- mean(y<exp(2*cos(x-pi)))
phat.under * 16 * pi
#from that distribution that fall under the curve we are trying to integrate. As we
#increase the number of points in the distribution, we get closer to
#expected answer.
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 1000000
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
#asas <- c(1,2,3)
#mean(asas>1)
phat.under <- mean(y<exp(2*cos(x-pi)))
phat.under * 16 * pi
#from that distribution that fall under the curve we are trying to integrate. As we
#increase the number of points in the distribution, we get closer to
#expected answer.
#what i do not understand here is the that why was mean used. We wanted
#the (count of numbers below the curve)/N where as what we are doing
#is (sum of numbers below the curve)/N
#that is because of the way mean is being used...it is being used on a logical
#condtion(1 or 0). And is thus summing up the 1 and 0 s which will actually give
#the count of 1's. And thus the mean of that is what we want. Example case
#showing the similarities is given below
N <- 10000000
x <- runif(N,0,2*pi)
y <- runif(N,0,8)
#asas <- c(1,2,3)
#mean(asas>1)
phat.under <- mean(y<exp(2*cos(x-pi)))
phat.under * 16 * pi
#integration using numerical integrate function
f <- function(x){exp(2*cos(x-pi))}
integrate(f,0,2*pi)
#integration using numerical integrate function
f <- function(x){exp(2*cos(x-pi))}
integrate(f,0,2*pi)
doone <- function(){
x <- rbinom(1,size = 50,prob = 1/6)
p <- x/50
p
}
doone()
p.sim <- replicate(1000,doone())
hist(p.sim,breaks = 15)
x <- rnorm(1000)
plot(density(x), xlim = c(-8,16))
# mean shifted 8 units to the right..but the curve is similar other than that
x <- rnorm(1000, mean = 8)
lines(density(x), col="blue")
#variation increase by increasing the sd value...so a bigger spread
lines(density(rnorm(1000,sd=2)), col="red")
lines(density(rnorm(1000,mean=8,sd=2)), col="green")
#still more variation due to bigger sd value
lines(density(rnorm(1000,sd=4)), col="purple")
lines(density(rnorm(1000,mean=8,sd=4)), col="cyan")
#Cleanse the ozone variable in the airquality data from missing values
my.ozone<-airquality$Ozone[!is.na(airquality$Ozone) & airquality$Ozone>1]
#my.ozone should be normally distributed, the best guess of the mean and
#standard deviation would be as follows
mean.1<-mean(my.ozone)
sd.1<-sd(my.ozone)
#Simulate a number of normally distributed numbers with mean mean.1 and standard
#deviation sd.1, equal to the amount of data in my.ozone
length(my.ozone)
set.seed(55789)
simulated.1<-rnorm(115,mean=mean.1,sd=sd.1)
#Compare the simulated values with my.ozone through qqplot()
#so what we trying to do here is that we have generated/simulated normal distribution
#values and now are  trying to find plot the values on graph and to see if there
#is linear correlation between the values(straight line). Shouldn't we have sorted the
#values in the 2 distributions before plotting??
#after sorting I got the same plot but i do not know why i got the same result without
#sorting..Ans: Q-Q plots take your sample data, sort it in ascending order, and then
#plot them
#qqplot(c(23,22,25),c(16,8,10))
#qqplot(sort(c(22,23,25)),sort(c(16,8,10)))
qqplot(simulated.1,my.ozone)
#Compare the simulated values with my.ozone through qqplot()
#so what we trying to do here is that we have generated/simulated normal distribution
#values and now are  trying to find plot the values on graph and to see if there
#is linear correlation between the values(straight line). Shouldn't we have sorted the
#values in the 2 distributions before plotting??
#after sorting I got the same plot but i do not know why i got the same result without
#sorting..Ans: Q-Q plots take your sample data, sort it in ascending order, and then
#plot them
#qqplot(c(23,22,25),c(16,8,10))
#qqplot(sort(c(22,23,25)),sort(c(16,8,10)))
qqplot(simulated.1,my.ozone)
lines(0:200,0:200,type="l",lwd=3,col="red")
qqplot(sort(simulated.1),sort(my.ozone))
lines(0:200,0:200,type="l",lwd=3,col="red")
#use ggplot to display same. Remember ggplot would not sort the data being plotted.
#So to get the same plot as qqplot, sort the data
#df <- data.frame(sim=c(23,22,25), nonsim=c(16,8,10))
#df <- data.frame(sim=sort(c(23,22,25)), nonsim=sort(c(16,8,10)))
#ggplot(data = df, aes(x= sim, y= nonsim)) + geom_point(aes(colour=nonsim)) + geom_text(aes(x=sim-0.05, y=nonsim-0.15, label=df$sim))
df <- data.frame(sim=sort(simulated.1), nonsim=sort(my.ozone))
ggplot(data = df, aes(x=sim, y=nonsim))+ geom_point(aes(colour=nonsim)) + geom_text(aes(x=sim-0.25, y=nonsim-2.45, label=sprintf("%0.2f", round(df$sim, digits = 2)), size=1))+
geom_text(aes(x=sim-0.25, y=nonsim+2.45, label=sprintf("%0.2f", round(df$nonsim, digits = 2)), size=1))
library(ggplot2)
ggplot(data = df, aes(x=sim, y=nonsim))+ geom_point(aes(colour=nonsim)) + geom_text(aes(x=sim-0.25, y=nonsim-2.45, label=sprintf("%0.2f", round(df$sim, digits = 2)), size=1))+
geom_text(aes(x=sim-0.25, y=nonsim+2.45, label=sprintf("%0.2f", round(df$nonsim, digits = 2)), size=1))
#consider a log-transform of the data. It might be that data are at different scales.
#So take log of both arrays and then plot to see correlation. If my.ozone data was normally
#distributed, it's plot against data from a nomally distribution would fit around a
#straight line. Wrong!!!that is now what we are trying to do here as we take
#exponential for plot!
#If the log-transformed data should be normally distributed, a best guess on
#mean and standard deviation would be as follows:
mean.2<-mean(log(my.ozone))
sd.2<-sd(log(my.ozone))
#now simulate the new values:
set.seed(8942)
simulated.2<-rnorm(115,mean=mean.2,sd=sd.2)
#Compare the exponential to the simulated points with my.ozone in a qqplot
qqplot(exp(simulated.2),my.ozone)
lines(0:200,0:200,type="l",lwd=3,col="red")
qqplot(simulated.2,my.ozone)
lines(0:200,0:200,type="l",lwd=3,col="red")
my.ozone
simulated.2
doone <- function(){
x <- sum(sample(1:6,2,replace=TRUE))
y<-sum(sample(1:6,x,replace=TRUE))
y
}
sum(sample(1:6,2,replace=TRUE))
sum(sample(1:6,x,replace=TRUE))
doone <- function(){
x <- sum(sample(1:6,2,replace=TRUE))
y<-sum(sample(1:6,x,replace=TRUE))
y
}
#simulate 1000 times
set.seed(457778)
y.values<-replicate(1000,doone())
hist(y.values)
box()
summary(y.values)
boxplot(y.values)
a<-rnorm(3, mean=2, sd=1)
a
b1<- c(3.373546, 4.183643, 3.164371)
summary(b1)
sd(b1)
b2<- c(1.373546, 2.183643, 1.164371)
summary(b2)
sd(b2)
b3<- c(5.373546, 6.183643, 5.164371 )
summary(b3)
sd(b3)
b4<- c(-2.626454, -1.816357, -2.835629)
summary(b4)
sd(b4)
n<-10000
doone <- function(){
x<-rbinom(1,50,1/6)
p<-x/50
p
}
p.sim<-replicate(n,doone())
length(p.sim)
summary(p.sim)
n<-100000
doone <- function(){
x<-rbinom(1,50,1/6)
p<-x/50
p
}
p.sim<-replicate(n,doone())
hist(p.sim,breaks=20)
n<-100000
doone <- function(){
x<-rbinom(1,50,1/6)
p<-x/50
p
}
p.sim<-replicate(n,doone())
hist(p.sim,breaks=20)
a<-rnorm(1000, mean=5, sd=1)
hist(a)
plot(density(a))
hist(a)
line(density(a))
line(density(a))
hist(a) + line(density(a))
hist(a)
plot(density(a))
my.data <- read.csv("Lab10.csv")
summary(my.data)
nrow(my.data)
ncol(my.data)
data1<-my.data$systolic.bp[my.data$Genotype=="BA"]
data2<-my.data$systolic.bp[my.data$Genotype=="BB"]
testResult <- t.test(data1,data2)
data1<-my.data$systolic.bp[my.data$Genotype=="BA"]
data2<-my.data$systolic.bp[my.data$Genotype=="BB"]
testResult <- t.test(data1,data2)
testResult
testResult
plot(density(data1))
plot(density(data1))
lines(density(data2))
hist(a)
lines(density(a))
plot(density(data1))
lines(density(data2))
n1 <- length(my.data[my.data$Genotype=="BA",c("Genotype")])
testResult <- t.test(runif(26,min=1, max=2),data2)
testResult
set.seed(1234)
my.new.data<-my.data
my.new.data$Genotype<-"BB"
index.temp<-sample(1:50,n1)
my.new.data$Genotype[index.temp]<-"BA"
new.data1<-my.new.data$systolic.bp[my.new.data$Genotype=="BA"]
new.data2<-my.new.data$systolic.bp[my.new.data$Genotype=="BB"]
t.test(new.data1,new.data2)$statistic
my.new.data<-my.data
my.new.data$Genotype<-"BB"
n1
index.temp<-sample(1:50,n1)
my.new.data$Genotype[index.temp]<-"BA"
index.temp
index.temp<-sample(1:50,n1)
my.new.data$Genotype[index.temp]<-"BA"
new.data1<-my.new.data$systolic.bp[my.new.data$Genotype=="BA"]
new.data2<-my.new.data$systolic.bp[my.new.data$Genotype=="BB"]
return(t.test(new.data1,new.data2)$statistic)
doone<-function(){
index.temp<-sample(1:50,n1)
my.new.data$Genotype[index.temp]<-"BA"
new.data1<-my.new.data$systolic.bp[my.new.data$Genotype=="BA"]
new.data2<-my.new.data$systolic.bp[my.new.data$Genotype=="BB"]
return(t.test(new.data1,new.data2)$statistic)
}
set.seed(554)
my.t.values<-replicate(100000,doone())
my.new.data<-my.data
my.new.data$Genotype<-"BB"
doone<-function(){
index.temp<-sample(1:50,n1)
my.new.data$Genotype[index.temp]<-"BA"
new.data1<-my.new.data$systolic.bp[my.new.data$Genotype=="BA"]
new.data2<-my.new.data$systolic.bp[my.new.data$Genotype=="BB"]
return(t.test(new.data1,new.data2)$statistic)
}
set.seed(554)
my.t.values<-replicate(100000,doone())
mean((1*(my.t.values)^2>2.027021^2))
